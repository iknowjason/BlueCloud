{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview Cyber Range deployment of HELK and Velociraptor! Automated terraform deployment of one system running HELK + Velociraptor server with one registered Windows endpoint in Azure or AWS. A collection of Terraform and Ansible scripts that automatically (and quickly) deploys a small HELK + Velociraptor R&D lab.","title":"Home"},{"location":"#overview","text":"Cyber Range deployment of HELK and Velociraptor! Automated terraform deployment of one system running HELK + Velociraptor server with one registered Windows endpoint in Azure or AWS. A collection of Terraform and Ansible scripts that automatically (and quickly) deploys a small HELK + Velociraptor R&D lab.","title":"Overview"},{"location":"apt/","text":"Running APT Simulation Tools This project includes three security tools to run APT simulations for generating forensic artifacts in an automated way. Here is a quick walkthrough on the three tools that are automatically deployed. To test efficacy of the detection solution, it is recommended to disable Windows Defender real-time protection setting. This will allow the simulation tools to run in an environment that will allow them to fully execute, allowing you to look deeper at the forensic artifacts. 1. Atomic Red Team (ART) The Atomic Red Team scripts are downloaded from the official Github repo [5] and the Invoke-AtomicRedTeam execution framework is automatically downloaded and imported from the following repo [6]. This allows you to more easily run atomic tests and the modules are imported into the powershell session everytime you launch a powershell session. This is controlled from the following powershell environment script: C:\\Users\\RTCAdmin\\Documents\\WindowsPowerShell\\Microsoft.Powershell_profile.ps1 Now that this is out of the way, let's show how to run an atomic test for ART! Remotely Running Atomics from Linux First, there is a python script that you can run to remotely invoke ART from your linux system. It's a simple wrapper to Ansible Playbook and the location of the script is here: PurpleCloud/modules/win10-vm/invoke-art.py Run it like this: python3 invoke-art.py The script looks for all hosts.cfg files in the working directory and runs the atomic tests against all host cfg files. If you only want to run against one of the hosts, run it with the -h flag. For example: python3 invoke-art.py -h hosts-Win10-Liem.cfg Running it with the -a flag will specify an atomic. python3 invoke-art.py -a T1558.003 The script looks for the atomic tests in windows index file: /modules/win10-vm/art/atomic-red-team/atomics/Indexes/Indexes-CSV/windows-index.csv Manually Running Atomics from the Windows System RDP into the Windows system. From a powershell session, simply run: PS C:\\ > Invoke-AtomicTest <ATOMIC_TEST> -PathToAtomicsFolder C:\\terraform\\ART\\atomic-red-team-master\\atomics The atomics are in the main project directory path of C:\\terraform\\ART\\atomic-red-team-master\\atomics . Browse through them to find which atomic test you want to run. Example of running T1007: PS C:\\Users\\RTCAdmin> Invoke-AtomicTest T1007 -PathToAtomicsFolder C:\\terraform\\ART\\atomic-red-team-master\\atomics 2. Elastic Detection Rules RTA (Red Team Attacks) scripts In June of 2020, Elastic open sourced their detection rules, including Python attack scripts through the Red Team Automation (RTA) project. The following repo [7] is automatically downloaded and extracted using Terraform and Ansible scripts. To run them, launch a cmd or powershell session and use python to run each test from the following directory: Change into the directory: C:\\terraform\\Elastic_Detections\\detection-rules-main Run each python script test that you wish. Each test is in the RTA directory and you invoke the test by removing the .py (TTPs are referenced as a name by just removing the last .py from the script): PS C:\\terraform\\Elastic_Detections\\detection-rules-main> python -m rta <TTP_NAME> Example of 'smb_connection' ttp: PS C:\\terraform\\Elastic_Detections\\detection-rules-main> python -m rta smb_connection You can browse all TTPs in the 'rta' sub-directory 3. APTSimulator The APTSimulator tool [8] is automatically downloaded. Simply extract the Zip archive and supply the zip password of 'apt'. C:\\terraform\\APTSimulator.zip Invoke a cmd prompt and run the batch file script: C:\\terraform\\ATPSimulator\\APTSimulator\\APTSimulator.bat","title":"Security Testing"},{"location":"apt/#running-apt-simulation-tools","text":"This project includes three security tools to run APT simulations for generating forensic artifacts in an automated way. Here is a quick walkthrough on the three tools that are automatically deployed. To test efficacy of the detection solution, it is recommended to disable Windows Defender real-time protection setting. This will allow the simulation tools to run in an environment that will allow them to fully execute, allowing you to look deeper at the forensic artifacts. 1. Atomic Red Team (ART) The Atomic Red Team scripts are downloaded from the official Github repo [5] and the Invoke-AtomicRedTeam execution framework is automatically downloaded and imported from the following repo [6]. This allows you to more easily run atomic tests and the modules are imported into the powershell session everytime you launch a powershell session. This is controlled from the following powershell environment script: C:\\Users\\RTCAdmin\\Documents\\WindowsPowerShell\\Microsoft.Powershell_profile.ps1 Now that this is out of the way, let's show how to run an atomic test for ART! Remotely Running Atomics from Linux First, there is a python script that you can run to remotely invoke ART from your linux system. It's a simple wrapper to Ansible Playbook and the location of the script is here: PurpleCloud/modules/win10-vm/invoke-art.py Run it like this: python3 invoke-art.py The script looks for all hosts.cfg files in the working directory and runs the atomic tests against all host cfg files. If you only want to run against one of the hosts, run it with the -h flag. For example: python3 invoke-art.py -h hosts-Win10-Liem.cfg Running it with the -a flag will specify an atomic. python3 invoke-art.py -a T1558.003 The script looks for the atomic tests in windows index file: /modules/win10-vm/art/atomic-red-team/atomics/Indexes/Indexes-CSV/windows-index.csv Manually Running Atomics from the Windows System RDP into the Windows system. From a powershell session, simply run: PS C:\\ > Invoke-AtomicTest <ATOMIC_TEST> -PathToAtomicsFolder C:\\terraform\\ART\\atomic-red-team-master\\atomics The atomics are in the main project directory path of C:\\terraform\\ART\\atomic-red-team-master\\atomics . Browse through them to find which atomic test you want to run. Example of running T1007: PS C:\\Users\\RTCAdmin> Invoke-AtomicTest T1007 -PathToAtomicsFolder C:\\terraform\\ART\\atomic-red-team-master\\atomics 2. Elastic Detection Rules RTA (Red Team Attacks) scripts In June of 2020, Elastic open sourced their detection rules, including Python attack scripts through the Red Team Automation (RTA) project. The following repo [7] is automatically downloaded and extracted using Terraform and Ansible scripts. To run them, launch a cmd or powershell session and use python to run each test from the following directory: Change into the directory: C:\\terraform\\Elastic_Detections\\detection-rules-main Run each python script test that you wish. Each test is in the RTA directory and you invoke the test by removing the .py (TTPs are referenced as a name by just removing the last .py from the script): PS C:\\terraform\\Elastic_Detections\\detection-rules-main> python -m rta <TTP_NAME> Example of 'smb_connection' ttp: PS C:\\terraform\\Elastic_Detections\\detection-rules-main> python -m rta smb_connection You can browse all TTPs in the 'rta' sub-directory 3. APTSimulator The APTSimulator tool [8] is automatically downloaded. Simply extract the Zip archive and supply the zip password of 'apt'. C:\\terraform\\APTSimulator.zip Invoke a cmd prompt and run the batch file script: C:\\terraform\\ATPSimulator\\APTSimulator\\APTSimulator.bat","title":"Running APT Simulation Tools"},{"location":"awsinstall/","text":"AWS Install AWS Requirements AWS Programmatic API keys Terraform: Tested on v0.14.7 Ansible: Tested on 2.9.6 Important Security Information: Security Groups Some people might be concerned about publicly exposing these cloud resources. By default, the security groups are wide open for all source prefixes. There is a variable that will whitelist your source prefix so that only the networks you specify will be allowed through AWS Security Groups. Make sure you pay close attention to the \"src_ip\" variable in step 5 below. AWS Installation Steps Note: Tested on Ubuntu 20.04 Step 1: Install Terraform and Ansible on your Linux system Download and install Terraform for your platform --> https://www.terraform.io/downloads.html Install Ansible $ sudo apt-get install ansible Step 2: Generate AWS programmatic API keys and take note of your access_key and secret_key. Step 3: Clone this repo $ git clone https://github.com/iknowjason/BlueCloud.git Step 4: First, copy the terraform.tfexample to terraform.tfvars. Next, using your favorite text editor, edit the terraform.tfvars file for the AWS resource provider matching your AWS API key values. cd BlueCloud/aws/deploy cp terraform.tfexample terraform.tfvars vi terraform.tfvars Edit these parameters in the terraform.tfvars file, replacing \"REPLACE_WITH_YOUR_VALUES\" to correctly match your AWS environment. access_key = \"REPLACE_WITH_YOUR_VALUES\" secret_key = \"REPLACE_WITH_YOUR_VALUES\" Your terraform.tfvars file should look similar to this but with your own AWS API key credentials. Note that these are sample fake credentials for demonstration purposes and not valid for any account: access_key = \"AKIAS3DPLMIHS7T7OWNU\" secret_key = \"MHEmms+6Rh1l4JB+ihDcFnFaSzE7xfRi8GMhUGzY\" Step 5: Edit the terraform.tfvars file to include your source network prefix for properly white listing AWS Security Groups. Edit the following file: deploy/terraform.tfvars At the bottom of the file, uncomment the \"src_ip\" variable and populate it with your correct source IP address. If you don't do this, the AWS Security Groups will open up your two VMs to the public Internet. Below is exactly where the variable should be uncommented and an example of what it looks like: # Set variable below for IP address prefix for white listing Azure NSG # uncomment variable below; otherwise, all of the public Internet will be permitted # https://ifconfig.me/ # curl https://ifconfig.me src_ip = \"192.168.87.4\" Step 6: Run the commands to initialize terraform and apply the resource plan $ cd BlueCloud/azure/deploy $ terraform init $ terraform apply -var-file=terraform.tfvars -auto-approve This should start the Terraform automated deployment plan Shutting down / cleaning up $ cd BlueCloud/aws/deploy $ ./destroy.sh","title":"AWS Install"},{"location":"awsinstall/#aws-install","text":"","title":"AWS Install"},{"location":"awsinstall/#aws-requirements","text":"AWS Programmatic API keys Terraform: Tested on v0.14.7 Ansible: Tested on 2.9.6","title":"AWS Requirements"},{"location":"awsinstall/#important-security-information-security-groups","text":"Some people might be concerned about publicly exposing these cloud resources. By default, the security groups are wide open for all source prefixes. There is a variable that will whitelist your source prefix so that only the networks you specify will be allowed through AWS Security Groups. Make sure you pay close attention to the \"src_ip\" variable in step 5 below.","title":"Important Security Information:  Security Groups"},{"location":"awsinstall/#aws-installation-steps","text":"Note: Tested on Ubuntu 20.04 Step 1: Install Terraform and Ansible on your Linux system Download and install Terraform for your platform --> https://www.terraform.io/downloads.html Install Ansible $ sudo apt-get install ansible Step 2: Generate AWS programmatic API keys and take note of your access_key and secret_key. Step 3: Clone this repo $ git clone https://github.com/iknowjason/BlueCloud.git Step 4: First, copy the terraform.tfexample to terraform.tfvars. Next, using your favorite text editor, edit the terraform.tfvars file for the AWS resource provider matching your AWS API key values. cd BlueCloud/aws/deploy cp terraform.tfexample terraform.tfvars vi terraform.tfvars Edit these parameters in the terraform.tfvars file, replacing \"REPLACE_WITH_YOUR_VALUES\" to correctly match your AWS environment. access_key = \"REPLACE_WITH_YOUR_VALUES\" secret_key = \"REPLACE_WITH_YOUR_VALUES\" Your terraform.tfvars file should look similar to this but with your own AWS API key credentials. Note that these are sample fake credentials for demonstration purposes and not valid for any account: access_key = \"AKIAS3DPLMIHS7T7OWNU\" secret_key = \"MHEmms+6Rh1l4JB+ihDcFnFaSzE7xfRi8GMhUGzY\" Step 5: Edit the terraform.tfvars file to include your source network prefix for properly white listing AWS Security Groups. Edit the following file: deploy/terraform.tfvars At the bottom of the file, uncomment the \"src_ip\" variable and populate it with your correct source IP address. If you don't do this, the AWS Security Groups will open up your two VMs to the public Internet. Below is exactly where the variable should be uncommented and an example of what it looks like: # Set variable below for IP address prefix for white listing Azure NSG # uncomment variable below; otherwise, all of the public Internet will be permitted # https://ifconfig.me/ # curl https://ifconfig.me src_ip = \"192.168.87.4\" Step 6: Run the commands to initialize terraform and apply the resource plan $ cd BlueCloud/azure/deploy $ terraform init $ terraform apply -var-file=terraform.tfvars -auto-approve This should start the Terraform automated deployment plan","title":"AWS Installation Steps"},{"location":"awsinstall/#shutting-down-cleaning-up","text":"$ cd BlueCloud/aws/deploy $ ./destroy.sh","title":"Shutting down / cleaning up"},{"location":"azureinstall/","text":"Installation Azure Requirements Azure tenant and subscription Terraform: Tested on v0.14.7 Ansible: Tested on 2.9.6 Important Security Information: Security Groups Some people might be concerned about publicly exposing these cloud resources. By default, the security groups are wide open for all source prefixes. There is a variable that will whitelist your source prefix so that only the networks you specify will be allowed through Azure NSGs. Make sure you pay close attention to the \"src_ip\" variable in step 7 below. Azure Installation Steps Note: Tested on Ubuntu 20.04 Step 1: Install Terraform and Ansible on your Linux system Download and install Terraform for your platform --> https://www.terraform.io/downloads.html Install Ansible $ sudo apt-get install ansible Step 2: Set up an Azure Service Principal on your Azure subscription that allows Terraform to automate tasks under your Azure subscription. Follow the exact instructions in this Microsoft link: https://docs.microsoft.com/en-us/azure/developer/terraform/getting-started-cloud-shell These were the two basic commands that were run based on this link above: az ad sp create-for-rbac --role=\"Owner\" --scopes=\"/subscriptions/<subscription_id>\" and this command below. From my testing I needed to use a role of \"Owner\" instead of \"Contributor\". Default Microsoft documentation shows role of \"Contributor\" which resulted in errors. az login --service-principal -u <service_principal_name> -p \"<service_principal_password>\" --tenant \"<service_principal_tenant>\" Take note of the following which we will use next to configure our Terraform Azure provider: subscription_id = \"\" client_id = \"\" client_secret = \"\" tenant_id = \"\" Step 3: Clone this repo $ git clone https://github.com/iknowjason/BlueCloud.git Step 4: First, copy the terraform.tfexample to terraform.tfvars. Next, using your favorite text editor, edit the terraform.tfvars file for the Azure resource provider matching your Azure Service Principal credentials. cd BlueCloud/azure/deploy cp terraform.tfexample terraform.tfvars vi terraform.tfvars Edit these parameters in the terraform.tfvars file, replacing \"REPLACE_WITH_YOUR_VALUES\" to correctly match your Azure environment. arm_client_id = \"REPLACE_WITH_YOUR_VALUES\" arm_client_secret = \"REPLACE_WITH_YOUR_VALUES\" subscription_id = \"REPLACE_WITH_YOUR_VALUES\" tenant_id = \"REPLACE_WITH_YOUR_VALUES\" Your terraform.tfvars file should look similar to this but with your own Azure Service Principal credentials. Note that these are fake credentials listed below for demonstration purposes. They are not valid account credentials that will work: arm_client_id = \"7e9c2cce-8bd4-987d-a2b0-70cd1e6e4781\" arm_client_secret = \":+O$+adfaadaF-?%:.?d/EYQLK6po9`|E<[\" subscription_id = \"aa9d8c9f-34c2-6262-89ff-3c67527c1b22\" tenant_id = \"8b6817d9-f209-2071-8f4f-cc03332847cb\" Step 5: Edit the terraform.tfvars file to include your source network prefix for properly white listing Azure Network Security Groups (NSGs). Edit the following file: deploy/terraform.tfvars At the bottom of the file, uncomment the \"src_ip\" variable and populate it with your correct source IP address. If you don't do this, the Azure NSGs will open up your two VMs to the public Internet. Below is exactly where the variable should be uncommented and an example of what it looks like: # Set variable below for IP address prefix for white listing Azure NSG # uncomment variable below; otherwise, all of the public Internet will be permitted # https://ifconfig.me/ # curl https://ifconfig.me src_ip = \"192.168.87.4\" Step 6: Run the commands to initialize terraform and apply the resource plan $ cd BlueCloud/azure/deploy $ terraform init $ terraform apply -var-file=terraform.tfvars -auto-approve This should start the Terraform automated deployment plan Shutting down / cleaning up $ cd BlueCloud/azure/deploy $ ./destroy.sh","title":"Azure Install"},{"location":"azureinstall/#installation","text":"","title":"Installation"},{"location":"azureinstall/#azure-requirements","text":"Azure tenant and subscription Terraform: Tested on v0.14.7 Ansible: Tested on 2.9.6","title":"Azure Requirements"},{"location":"azureinstall/#important-security-information-security-groups","text":"Some people might be concerned about publicly exposing these cloud resources. By default, the security groups are wide open for all source prefixes. There is a variable that will whitelist your source prefix so that only the networks you specify will be allowed through Azure NSGs. Make sure you pay close attention to the \"src_ip\" variable in step 7 below.","title":"Important Security Information:  Security Groups"},{"location":"azureinstall/#azure-installation-steps","text":"Note: Tested on Ubuntu 20.04 Step 1: Install Terraform and Ansible on your Linux system Download and install Terraform for your platform --> https://www.terraform.io/downloads.html Install Ansible $ sudo apt-get install ansible Step 2: Set up an Azure Service Principal on your Azure subscription that allows Terraform to automate tasks under your Azure subscription. Follow the exact instructions in this Microsoft link: https://docs.microsoft.com/en-us/azure/developer/terraform/getting-started-cloud-shell These were the two basic commands that were run based on this link above: az ad sp create-for-rbac --role=\"Owner\" --scopes=\"/subscriptions/<subscription_id>\" and this command below. From my testing I needed to use a role of \"Owner\" instead of \"Contributor\". Default Microsoft documentation shows role of \"Contributor\" which resulted in errors. az login --service-principal -u <service_principal_name> -p \"<service_principal_password>\" --tenant \"<service_principal_tenant>\" Take note of the following which we will use next to configure our Terraform Azure provider: subscription_id = \"\" client_id = \"\" client_secret = \"\" tenant_id = \"\" Step 3: Clone this repo $ git clone https://github.com/iknowjason/BlueCloud.git Step 4: First, copy the terraform.tfexample to terraform.tfvars. Next, using your favorite text editor, edit the terraform.tfvars file for the Azure resource provider matching your Azure Service Principal credentials. cd BlueCloud/azure/deploy cp terraform.tfexample terraform.tfvars vi terraform.tfvars Edit these parameters in the terraform.tfvars file, replacing \"REPLACE_WITH_YOUR_VALUES\" to correctly match your Azure environment. arm_client_id = \"REPLACE_WITH_YOUR_VALUES\" arm_client_secret = \"REPLACE_WITH_YOUR_VALUES\" subscription_id = \"REPLACE_WITH_YOUR_VALUES\" tenant_id = \"REPLACE_WITH_YOUR_VALUES\" Your terraform.tfvars file should look similar to this but with your own Azure Service Principal credentials. Note that these are fake credentials listed below for demonstration purposes. They are not valid account credentials that will work: arm_client_id = \"7e9c2cce-8bd4-987d-a2b0-70cd1e6e4781\" arm_client_secret = \":+O$+adfaadaF-?%:.?d/EYQLK6po9`|E<[\" subscription_id = \"aa9d8c9f-34c2-6262-89ff-3c67527c1b22\" tenant_id = \"8b6817d9-f209-2071-8f4f-cc03332847cb\" Step 5: Edit the terraform.tfvars file to include your source network prefix for properly white listing Azure Network Security Groups (NSGs). Edit the following file: deploy/terraform.tfvars At the bottom of the file, uncomment the \"src_ip\" variable and populate it with your correct source IP address. If you don't do this, the Azure NSGs will open up your two VMs to the public Internet. Below is exactly where the variable should be uncommented and an example of what it looks like: # Set variable below for IP address prefix for white listing Azure NSG # uncomment variable below; otherwise, all of the public Internet will be permitted # https://ifconfig.me/ # curl https://ifconfig.me src_ip = \"192.168.87.4\" Step 6: Run the commands to initialize terraform and apply the resource plan $ cd BlueCloud/azure/deploy $ terraform init $ terraform apply -var-file=terraform.tfvars -auto-approve This should start the Terraform automated deployment plan","title":"Azure Installation Steps"},{"location":"azureinstall/#shutting-down-cleaning-up","text":"$ cd BlueCloud/azure/deploy $ ./destroy.sh","title":"Shutting down / cleaning up"},{"location":"cost/","text":"Cost Analysis Important Information As this tool spins up cloud resources, it will result in charges to your Azure or AWS account. Efforts have been made to minimize the costs incurred, but the tool author is not responsible for any charges or security issues that may result from usage of this tool. Be sure to tear down all resources when not using them. Azure Cost Analysis Use the Cost Analysis feature of Azure to measure the daily cost of the enabled resources. Here are some approximate figures with standing up a new subscription and resource group and then running BlueCloud. The approximate cost is $71.31 after running the lab for 7 days. Day 5 was the last day of the billing month, which might explain the increase at end of billing month. Table: Azure Accrued Costs Days Running Costs Accrued 1 day $4.94 2 days $17.52 3 days $27.39 4 days $35.93 5 days $47.61 6 days $59.64 7 days $71.31 Screen Shot from Azure Subscription Here is a screen shot showing costs accrued from a new installation on my subscription after 7 days. AWS Cost Analysis Below are some samples on a new installation of running BlueCloud on AWS. The billing feature took a few days to render accrued costs, so it starts at day 4. Day 5 is the last day of billing month. Table: Accrued AWS Costs Days Running Costs Accrued 4 days $21.01 5 days $25.04 6 days $28.34 7 days $37.10 Screen Shot from AWS Subscription Here is a screen shot showing costs accrued from a new installation on my subscription after 7 days.","title":"Cost"},{"location":"cost/#cost-analysis","text":"","title":"Cost Analysis"},{"location":"cost/#important-information","text":"As this tool spins up cloud resources, it will result in charges to your Azure or AWS account. Efforts have been made to minimize the costs incurred, but the tool author is not responsible for any charges or security issues that may result from usage of this tool. Be sure to tear down all resources when not using them.","title":"Important Information"},{"location":"cost/#azure-cost-analysis","text":"Use the Cost Analysis feature of Azure to measure the daily cost of the enabled resources. Here are some approximate figures with standing up a new subscription and resource group and then running BlueCloud. The approximate cost is $71.31 after running the lab for 7 days. Day 5 was the last day of the billing month, which might explain the increase at end of billing month.","title":"Azure Cost Analysis"},{"location":"cost/#table-azure-accrued-costs","text":"Days Running Costs Accrued 1 day $4.94 2 days $17.52 3 days $27.39 4 days $35.93 5 days $47.61 6 days $59.64 7 days $71.31","title":"Table:  Azure Accrued Costs"},{"location":"cost/#screen-shot-from-azure-subscription","text":"Here is a screen shot showing costs accrued from a new installation on my subscription after 7 days.","title":"Screen Shot from Azure Subscription"},{"location":"cost/#aws-cost-analysis","text":"Below are some samples on a new installation of running BlueCloud on AWS. The billing feature took a few days to render accrued costs, so it starts at day 4. Day 5 is the last day of billing month.","title":"AWS Cost Analysis"},{"location":"cost/#table-accrued-aws-costs","text":"Days Running Costs Accrued 4 days $21.01 5 days $25.04 6 days $28.34 7 days $37.10","title":"Table:  Accrued AWS Costs"},{"location":"cost/#screen-shot-from-aws-subscription","text":"Here is a screen shot showing costs accrued from a new installation on my subscription after 7 days.","title":"Screen Shot from AWS Subscription"},{"location":"credits/","text":"Credits @ghostinthewires for his Terraform templates (https://github.com/ghostinthewires) @mosesrenegade for his Ansible Playbook integration with Terraform + Powershell script (https://github.com/mosesrenegade)","title":"Credits"},{"location":"credits/#credits","text":"@ghostinthewires for his Terraform templates (https://github.com/ghostinthewires) @mosesrenegade for his Ansible Playbook integration with Terraform + Powershell script (https://github.com/mosesrenegade)","title":"Credits"},{"location":"infrastructure/","text":"Infrastructure and Credentials Velociraptor + HELK Internal IP 10.100.1.5 Windows VM Internal IP 10.100.30.11 Windows VM Local Administrator credentials: RTCAdmin:Password123 Subnets 10.100.1.0/24 (Server Subnet with HELK + Velociraptor) 10.100.30.0/24 (User Subnet with Windows Endpoint) HELK + Velociraptor Linux OS username (Azure) helk (Uses SSH public key auth) HELK + Velociraptor Linux OS username (AWS) ubuntu (Uses SSH public key auth) HELK Kibana Administrator Password for https port 443 helk:hunting Velociraptor GUI Administrator Password for Port 8889 helk:helk Windows OS in Azure: Windows 10 Pro Windows OS in AWS: Windows 2019 Server Remote Access Velociraptor + HELK Server: View contents of modules/velocihelk-vm/hosts.cfg. The second line should show the IP address of the Velociraptor + HELK server that is provisioned a public IP from Azure or AWS. You can SSH to the host from within that directory: $ ssh -i ssh_key.pem helk@<IP ADDRESS> Kibana GUI: Use the step above to get the public Azure or AWS IP address of the HELK Server. Use Firefox browser to navigate to: https://<IP ADDRESS> Velociraptor GUI: Use the step above to get the public Azure or AWS IP address of the Velociraptor Server. Use Firefox browser to navigate to: https://<IP ADDRESS>:8889 Windows Systems: For remote RDP access to the Windows 2019 Server or Windows 10 Pro endpoints: Change into correct modules directory and view contents of hosts.cfg. The second line should show the public IP address provisioned by Azure or AWS. Just RDP to it with local Admin credentials above. The Windows Server will be located in the /modules/dc-vm/hosts.cfg . The Windows endpoints will be in the directory: /modules/win10-vm .","title":"Creds and Access"},{"location":"infrastructure/#infrastructure-and-credentials","text":"Velociraptor + HELK Internal IP 10.100.1.5 Windows VM Internal IP 10.100.30.11 Windows VM Local Administrator credentials: RTCAdmin:Password123 Subnets 10.100.1.0/24 (Server Subnet with HELK + Velociraptor) 10.100.30.0/24 (User Subnet with Windows Endpoint) HELK + Velociraptor Linux OS username (Azure) helk (Uses SSH public key auth) HELK + Velociraptor Linux OS username (AWS) ubuntu (Uses SSH public key auth) HELK Kibana Administrator Password for https port 443 helk:hunting Velociraptor GUI Administrator Password for Port 8889 helk:helk Windows OS in Azure: Windows 10 Pro Windows OS in AWS: Windows 2019 Server","title":"Infrastructure and Credentials"},{"location":"infrastructure/#remote-access","text":"Velociraptor + HELK Server: View contents of modules/velocihelk-vm/hosts.cfg. The second line should show the IP address of the Velociraptor + HELK server that is provisioned a public IP from Azure or AWS. You can SSH to the host from within that directory: $ ssh -i ssh_key.pem helk@<IP ADDRESS> Kibana GUI: Use the step above to get the public Azure or AWS IP address of the HELK Server. Use Firefox browser to navigate to: https://<IP ADDRESS> Velociraptor GUI: Use the step above to get the public Azure or AWS IP address of the Velociraptor Server. Use Firefox browser to navigate to: https://<IP ADDRESS>:8889 Windows Systems: For remote RDP access to the Windows 2019 Server or Windows 10 Pro endpoints: Change into correct modules directory and view contents of hosts.cfg. The second line should show the public IP address provisioned by Azure or AWS. Just RDP to it with local Admin credentials above. The Windows Server will be located in the /modules/dc-vm/hosts.cfg . The Windows endpoints will be in the directory: /modules/win10-vm .","title":"Remote Access"},{"location":"overview/","text":"Use Cases EDR Testing lab PoC / Product Security Lab Penetration Testing lab SIEM / Threat Hunting / DFIR / Live Response lab with HELK + Velociraptor [1, 2] Data Science research with HELK server, Jupyter notebooks Detection Engineering research with Mordor [3, 4] Features and Information New Feature: Combined Velociraptor + HELK System! Velociraptor [1] + Hunting ELK [2] System: Windows 10 Endpoints instrumented with agents to auto register Velociraptor and send Sysmon logs New Feature: Three tools for Adversary Simulation: Script to automatically invoke Atomic Red Team unit tests using Ansible playbook. New Feature: Support for AWS and Azure - Terraform provider support for AWS, Azure. Deploys one Linux 18.04 HELK Server with data science capabiliies. Deploys HELK install option #4, including KAFKA + KSQL + ELK + NGNIX + SPARK + JUPYTER + ELASTALERT Windows endpoint is automatically configured with Sysmon (SwiftOnSecurity) and Winlogbeat Windows endpoint is automatically configured to use HELK configuration + Kafka Winlogbeat output to send logs to HELK Automatically registers the Windows endpoint to the Velociraptor server with TLS self-signed certificate configuration Windows endpoint includes Atomic Red Team (ART), Elastic Detection RTA, and APTSimulator Uses Terraform templates to automatically deploy in Azure with VMs Terraform templates write customizable Ansible Playbook configuration Azure NSGs and AWS Security Groups can whitelist your source prefix (for added security) The following ports are opened through Azure and AWS Security Groups for ingress TCP traffic: RDP (3389), WinRM HTTP (5985), WinRM HTTPS (5986), SSH (22), HTTPS (443), Spark (8080), KQL (8088), Zookeeper (2181), Velociraptor GUI (8889), Velociraptor Agent (8000) Approximate build time: 16 minutes","title":"Overview"},{"location":"overview/#use-cases","text":"EDR Testing lab PoC / Product Security Lab Penetration Testing lab SIEM / Threat Hunting / DFIR / Live Response lab with HELK + Velociraptor [1, 2] Data Science research with HELK server, Jupyter notebooks Detection Engineering research with Mordor [3, 4]","title":"Use Cases"},{"location":"overview/#features-and-information","text":"New Feature: Combined Velociraptor + HELK System! Velociraptor [1] + Hunting ELK [2] System: Windows 10 Endpoints instrumented with agents to auto register Velociraptor and send Sysmon logs New Feature: Three tools for Adversary Simulation: Script to automatically invoke Atomic Red Team unit tests using Ansible playbook. New Feature: Support for AWS and Azure - Terraform provider support for AWS, Azure. Deploys one Linux 18.04 HELK Server with data science capabiliies. Deploys HELK install option #4, including KAFKA + KSQL + ELK + NGNIX + SPARK + JUPYTER + ELASTALERT Windows endpoint is automatically configured with Sysmon (SwiftOnSecurity) and Winlogbeat Windows endpoint is automatically configured to use HELK configuration + Kafka Winlogbeat output to send logs to HELK Automatically registers the Windows endpoint to the Velociraptor server with TLS self-signed certificate configuration Windows endpoint includes Atomic Red Team (ART), Elastic Detection RTA, and APTSimulator Uses Terraform templates to automatically deploy in Azure with VMs Terraform templates write customizable Ansible Playbook configuration Azure NSGs and AWS Security Groups can whitelist your source prefix (for added security) The following ports are opened through Azure and AWS Security Groups for ingress TCP traffic: RDP (3389), WinRM HTTP (5985), WinRM HTTPS (5986), SSH (22), HTTPS (443), Spark (8080), KQL (8088), Zookeeper (2181), Velociraptor GUI (8889), Velociraptor Agent (8000) Approximate build time: 16 minutes","title":"Features and Information"},{"location":"references/","text":"References [1] Velociraptor Website: https://www.velocidex.com/ [2] HELK Website: https://github.com/Cyb3rWard0g/HELK [3] Mordor Website: https://mordordatasets.com/introduction.html [4] Mordor Use Case: https://posts.specterops.io/enter-mordor-pre-recorded-security-events-from-simulated-adversarial-techniques-fdf5555c9eb1 [5] Atomic Red Team: https://github.com/redcanaryco/atomic-red-team [6] Invoke ART: https://github.com/redcanaryco/invoke-atomicredteam [7] Elastic Detection Rules: https://github.com/elastic/detection-rules [8] APTSimulator: https://github.com/NextronSystems/APTSimulator","title":"References"},{"location":"references/#references","text":"[1] Velociraptor Website: https://www.velocidex.com/ [2] HELK Website: https://github.com/Cyb3rWard0g/HELK [3] Mordor Website: https://mordordatasets.com/introduction.html [4] Mordor Use Case: https://posts.specterops.io/enter-mordor-pre-recorded-security-events-from-simulated-adversarial-techniques-fdf5555c9eb1 [5] Atomic Red Team: https://github.com/redcanaryco/atomic-red-team [6] Invoke ART: https://github.com/redcanaryco/invoke-atomicredteam [7] Elastic Detection Rules: https://github.com/elastic/detection-rules [8] APTSimulator: https://github.com/NextronSystems/APTSimulator","title":"References"},{"location":"remoteaccess/","text":"Remote Access Velociraptor + HELK Server: View contents of modules/velocihelk-vm/hosts.cfg. The second line should show the IP address of the Velociraptor + HELK server that is provisioned a public IP from Azure. You can SSH to the host from within that directory: $ ssh -i ssh_key.pem helk@<IP ADDRESS> Kibana GUI: Use the step above to get the public Azure IP address of the HELK Server. Use Firefox browser to navigate to: https://<IP ADDRESS> Velociraptor GUI: Use the step above to get the public Azure IP address of the Velociraptor Server. Use Firefox browser to navigate to: https://<IP ADDRESS>:8889 Windows Systems: For remote RDP access to the Windows 2019 Server or Windows 10 Pro endpoints: Change into correct modules directory and view contents of hosts.cfg. The second line should show the public IP address provisioned by Azure. Just RDP to it with local Admin credentials above. The Windows Server will be located in the /modules/dc-vm/hosts.cfg . The Windows endpoints will be in the directory: /modules/win10-vm .","title":"Remote Access"},{"location":"remoteaccess/#remote-access","text":"Velociraptor + HELK Server: View contents of modules/velocihelk-vm/hosts.cfg. The second line should show the IP address of the Velociraptor + HELK server that is provisioned a public IP from Azure. You can SSH to the host from within that directory: $ ssh -i ssh_key.pem helk@<IP ADDRESS> Kibana GUI: Use the step above to get the public Azure IP address of the HELK Server. Use Firefox browser to navigate to: https://<IP ADDRESS> Velociraptor GUI: Use the step above to get the public Azure IP address of the Velociraptor Server. Use Firefox browser to navigate to: https://<IP ADDRESS>:8889 Windows Systems: For remote RDP access to the Windows 2019 Server or Windows 10 Pro endpoints: Change into correct modules directory and view contents of hosts.cfg. The second line should show the public IP address provisioned by Azure. Just RDP to it with local Admin credentials above. The Windows Server will be located in the /modules/dc-vm/hosts.cfg . The Windows endpoints will be in the directory: /modules/win10-vm .","title":"Remote Access"}]}